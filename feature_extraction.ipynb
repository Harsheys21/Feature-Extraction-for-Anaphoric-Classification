{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3296a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69c3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "155cc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/it-corpus.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0667d640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NomAnaph</td>\n",
       "      <td>Nevertheless,  in  view  of  the  world-wide  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ClauseAnaph</td>\n",
       "      <td>It's  simply  bare-faced  fortune  hunting;  b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NomAnaph</td>\n",
       "      <td>Mary  was  situated  about  two  miles  from  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ClauseAnaph</td>\n",
       "      <td>She  is  up  at  five  every  morning  to  mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ClauseAnaph</td>\n",
       "      <td>Don't  say  it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>NomAnaph</td>\n",
       "      <td>I  was  fairly  certain  that  it  was  Mr.s. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>ClauseAnaph</td>\n",
       "      <td>It  all  arose  from  a  misunderstanding.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>ClauseAnaph</td>\n",
       "      <td>He  knew  it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>NomAnaph</td>\n",
       "      <td>Pardon  me,  mon  ami,  but  you  did  not  un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>ClauseAnaph</td>\n",
       "      <td>I  could  have  cleared  him...though  it  mig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Class                                           Sentence\n",
       "0       NomAnaph  Nevertheless,  in  view  of  the  world-wide  ...\n",
       "1    ClauseAnaph  It's  simply  bare-faced  fortune  hunting;  b...\n",
       "2       NomAnaph  Mary  was  situated  about  two  miles  from  ...\n",
       "3    ClauseAnaph  She  is  up  at  five  every  morning  to  mil...\n",
       "4    ClauseAnaph                                   Don't  say  it. \n",
       "..           ...                                                ...\n",
       "508     NomAnaph  I  was  fairly  certain  that  it  was  Mr.s. ...\n",
       "509  ClauseAnaph        It  all  arose  from  a  misunderstanding. \n",
       "510  ClauseAnaph                                     He  knew  it. \n",
       "511     NomAnaph  Pardon  me,  mon  ami,  but  you  did  not  un...\n",
       "512  ClauseAnaph  I  could  have  cleared  him...though  it  mig...\n",
       "\n",
       "[513 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a617318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c22866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object of preposition\n"
     ]
    }
   ],
   "source": [
    "description = spacy.explain(\"pobj\")\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    sentence = row.Sentence\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # obtain f1\n",
    "    f_one = -1\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.text.lower() == 'it' and token.pos_ == \"PRON\":\n",
    "            f_one = i + 1\n",
    "            break\n",
    "    \n",
    "    it_index = f_one - 1\n",
    "    \n",
    "    # obtain f2\n",
    "    f_two = len(doc)\n",
    "    \n",
    "    #obtain f3\n",
    "    f_three = 0\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.is_punct:\n",
    "            f_three+=1\n",
    "            \n",
    "    #obtain f4\n",
    "    f_four = 0\n",
    "    for np in doc.noun_chunks:\n",
    "        if np.end <= it_index:\n",
    "            f_four +=1\n",
    "            \n",
    "    #obtain f5\n",
    "    f_five = 0\n",
    "    for np in doc.noun_chunks:\n",
    "        if np.start > it_index:\n",
    "            f_five += 1\n",
    "            \n",
    "    #obtain f6\n",
    "    f_six = False\n",
    "    for tok in doc:\n",
    "        if tok.pos_ == \"ADP\":  \n",
    "            end_i = max(t.i for t in tok.subtree)\n",
    "            if end_i == it_index - 1:\n",
    "                f_six = True\n",
    "    \n",
    "    #obtain f7\n",
    "    f_seven = ['ABS','ABS','ABS','ABS','ABS','ABS','ABS','ABS']    \n",
    "    preceding = doc[max(0, it_index-4):it_index]\n",
    "    for i, token in enumerate(preceding):\n",
    "        f_seven[4 - len(preceding) + i] = token.pos_\n",
    "        \n",
    "    succeding = doc[it_index + 1:it_index + 5]\n",
    "    for i, token in enumerate(succeding):\n",
    "        f_seven[4 + i] = token.pos_\n",
    "    \n",
    "    #obtain f8\n",
    "    f_eight = False\n",
    "    if f_one < len(doc):\n",
    "        if doc[f_one].text.lower().endswith('ing') and doc[f_one].pos_ == 'VERB':\n",
    "            f_eight = True\n",
    "    \n",
    "    #obtain f9\n",
    "    f_nine = False\n",
    "    if f_one < len(doc):\n",
    "        if doc[f_one].pos_ == \"ADP\":\n",
    "            f_nine = True\n",
    "    \n",
    "    #obtain f10\n",
    "    f_ten = 0\n",
    "    for i in range(it_index+1, len(doc)):\n",
    "        if doc[i].pos_ == \"ADJ\":\n",
    "            f_ten += 1\n",
    "            \n",
    "    #obtain f11\n",
    "    f_eleven = False\n",
    "    if it_index-1 >= 0:\n",
    "        if doc[it_index - 1].pos_ == \"VERB\":\n",
    "            f_eleven = True\n",
    "    \n",
    "    #obtain f12\n",
    "    f_twelve = False\n",
    "    if it_index + 1 < len(doc):\n",
    "        if doc[it_index + 1].pos_ == \"VERB\":\n",
    "            f_twelve = True\n",
    "\n",
    "    #obtain f13\n",
    "    f_thirteen = False\n",
    "    if it_index + 1 < len(doc):\n",
    "        if doc[it_index + 1].pos_ == \"ADJ\":\n",
    "            f_thirteen = True\n",
    "    \n",
    "    #obtain f14\n",
    "    f_fourteen = False\n",
    "    for np in doc.noun_chunks:\n",
    "        if np.start > it_index:\n",
    "            for t in np:\n",
    "                if t.pos_ == \"ADJ\":\n",
    "                    f_fourteen = True\n",
    "                    break\n",
    "    \n",
    "    #obtain f15\n",
    "    f_fifteen = 0\n",
    "    for i in range(len(doc) - 1):\n",
    "        if doc[i].lemma_ == \"to\" and doc[i].pos_ in {\"PART\", \"ADP\"} and doc[i+1].pos_ == \"VERB\":\n",
    "            f_fifteen = i + 1\n",
    "            break\n",
    "    \n",
    "    #obtain 16\n",
    "    f_sixteen = 0\n",
    "    for j in range(it_index + 1, len(doc)):\n",
    "        if doc[j].pos_ == \"ADP\":\n",
    "            f_sixteen = j - it_index - 1\n",
    "            break\n",
    "\n",
    "    \n",
    "    #obtain f17\n",
    "    f_seventeen = False\n",
    "    np_starts = []\n",
    "    for np in doc.noun_chunks:\n",
    "        if np.start > it_index:\n",
    "            np_starts.append(np.start)\n",
    "        \n",
    "    j = it_index + 1\n",
    "    while j < len(doc) - 1:\n",
    "        if doc[j].pos_ == \"ADJ\":\n",
    "            if (j + 1) in np_starts:\n",
    "                f_seventeen = True\n",
    "                break\n",
    "        j += 1\n",
    "\n",
    "    #obtain f18\n",
    "    f_eighteen = doc[it_index].dep_\n",
    "\n",
    "    #obtain f19\n",
    "    f_nineteen = False\n",
    "    if it_index+1 < len(doc) and doc[it_index+1].pos_ == \"VERB\":\n",
    "        synsets = wn.synsets(doc[it_index+1].lemma_, pos=wn.VERB)\n",
    "        f_nineteen = any(s.lexname() == 'verb.weather' for s in synsets)\n",
    "\n",
    "    #obtain f20\n",
    "    f_twenty = False\n",
    "    if it_index+1 < len(doc) and doc[it_index+1].pos_ == \"VERB\":\n",
    "        synsets = wn.synsets(doc[it_index+1].lemma_, pos=wn.VERB)\n",
    "        f_twenty = any(s.lexname() == 'verb.cognition' for s in synsets)\n",
    "        \n",
    "    return {\n",
    "        \"F1\": f_one, \"F2\": f_two, \"F3\": f_three, \"F4\": f_four, \"F5\": f_five,\n",
    "        \"F6\": f_six, \"F7\": f_seven, \"F8\": f_eight, \"F9\": f_nine, \"F10\": f_ten,\n",
    "        \"F11\": f_eleven, \"F12\": f_twelve, \"F13\": f_thirteen, \"F14\": f_fourteen, \"F15\": f_fifteen,\n",
    "        \"F16\": f_sixteen, \"F17\": f_seventeen, \"F18\": f_eighteen, \"F19\": f_nineteen, \"F20\": f_twenty\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a6935d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nevertheless\n",
      "It\n",
      "Mary\n",
      "She\n",
      "Do\n",
      "In\n",
      "The\n",
      "It\n",
      "It\n",
      "And\n",
      "But\n",
      "Do\n",
      "Might\n",
      "Associate\n",
      "It\n",
      "She\n",
      "Well\n",
      "I\n",
      "I\n",
      "Yes\n",
      "We\n",
      "Cynthia\n",
      "So\n",
      "Well\n",
      "The\n",
      "His\n",
      "Mary\n",
      "Then\n",
      "I\n",
      "It\n",
      "I\n",
      "I\n",
      "He\n",
      "He\n",
      "He\n",
      "It\n",
      "It\n",
      "The\n",
      "The\n",
      "The\n",
      "We\n",
      "Wilkins\n",
      "I\n",
      "And\n",
      "He\n",
      "She\n",
      "Therefore\n",
      "In\n",
      "He\n",
      "He\n",
      "He\n",
      "He\n",
      "He\n",
      "He\n",
      "It\n",
      "However\n",
      "He\n",
      "A\n",
      "Poirot\n",
      "Mon\n",
      "Mon\n",
      "Mon\n",
      "It\n",
      "It\n",
      "But\n",
      "He\n",
      "Finally\n",
      "No\n",
      "It\n",
      "It\n",
      "It\n",
      "I\n",
      "The\n",
      "I\n",
      "We\n",
      "It\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "She\n",
      "What\n",
      "Well\n",
      "She\n",
      "She\n",
      "She\n",
      "She\n",
      "She\n",
      "That\n",
      "I\n",
      "Ah\n",
      "poirot\n",
      "Five\n",
      "I\n",
      "A\n",
      "It\n",
      "But\n",
      "I\n",
      "It\n",
      "Yes\n",
      "Yes\n",
      "What\n",
      "Who\n",
      "Did\n",
      "No\n",
      "Then\n",
      "Then\n",
      "Then\n",
      "The\n",
      "And\n",
      "What\n",
      "And\n",
      "Annie\n",
      "What\n",
      "Seeing\n",
      "Coarse\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "So\n",
      "So\n",
      "I\n",
      "Yes\n",
      "It\n",
      "I\n",
      "I\n",
      "She\n",
      "Yes\n",
      "That\n",
      "It\n",
      "It\n",
      "It\n",
      "It\n",
      "He\n",
      "It\n",
      "A\n",
      "The\n",
      "Yes\n",
      "But\n",
      "I\n",
      "Is\n",
      "I\n",
      "I\n",
      "We\n",
      "I\n",
      "I\n",
      "If\n",
      "If\n",
      "If\n",
      "The\n",
      "Surely\n",
      "It\n",
      "It\n",
      "You\n",
      "No\n",
      "It\n",
      "It\n",
      "Can\n",
      "I\n",
      "It\n",
      "It\n",
      "Where\n",
      "He\n",
      "He\n",
      "In\n",
      "If\n",
      "Dorcas\n",
      "Manning\n",
      "He\n",
      "She\n",
      "What\n",
      "Well\n",
      "Well\n",
      "Mr.\n",
      "John\n",
      "How\n",
      "Now\n",
      "Find\n",
      "Do\n",
      "Do\n",
      "Taking\n",
      "I\n",
      "But\n",
      "But\n",
      "As\n",
      "Probably\n",
      "It\n",
      "It\n",
      "Finding\n",
      "I\n",
      "And\n",
      "It\n",
      "It\n",
      "It\n",
      "I\n",
      "What\n",
      "It\n",
      "It\n",
      "It\n",
      "Did\n",
      "And\n",
      "To\n",
      "I\n",
      "It\n",
      "You\n",
      "That\n",
      "Now\n",
      "Now\n",
      "Every\n",
      "She\n",
      "For\n",
      "It\n",
      "It\n",
      "Shorn\n",
      "The\n",
      "It\n",
      "No\n",
      "It\n",
      "cocoa\n",
      "Dr\n",
      "Sounded\n",
      "My\n",
      "Strychnine\n",
      "Dorcas\n",
      "Dorcas\n",
      "The\n",
      "Poirot\n",
      "It\n",
      "I\n",
      "I\n",
      "I\n",
      "It\n",
      "Will\n",
      "He\n",
      "It\n",
      "He\n",
      "He\n",
      "It\n",
      "But\n",
      "You\n",
      "But\n",
      "The\n",
      "I\n",
      "But\n",
      "When\n",
      "But\n",
      "I\n",
      "It\n",
      "I\n",
      "It\n",
      "No\n",
      "Because\n",
      "He\n",
      "Would\n",
      "And\n",
      "It\n",
      "Oh\n",
      "Did\n",
      "No\n",
      "The\n",
      "But\n",
      "That\n",
      "But\n",
      "My\n",
      "I\n",
      "It\n",
      "No\n",
      "We\n",
      "I\n",
      "I\n",
      "You\n",
      "It\n",
      "She\n",
      "My\n",
      "But\n",
      "But\n",
      "Dr\n",
      "Dr\n",
      "I\n",
      "Well\n",
      "It\n",
      "Naturally\n",
      "It\n",
      "We\n",
      "He\n",
      "He\n",
      "He\n",
      "After\n",
      "After\n",
      "I\n",
      "And\n",
      "I\n",
      "And\n",
      "And\n",
      "Burnt\n",
      "Do\n",
      "You\n",
      "It\n",
      "Who\n",
      "You\n",
      "I\n",
      "I\n",
      "It\n",
      "If\n",
      "If\n",
      "If\n",
      "He\n",
      "I\n",
      "I\n",
      "You\n",
      "But\n",
      "It\n",
      "Oh\n",
      "It\n",
      "It\n",
      "I\n",
      "Let\n",
      "It\n",
      "The\n",
      "Otherwise\n",
      "A\n",
      "A\n",
      "Say\n",
      "What\n",
      "Certainly\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "But\n",
      "I\n",
      "Do\n",
      "It\n",
      "After\n",
      "It\n",
      "I\n",
      "Probably\n",
      "Of\n",
      "It\n",
      "She\n",
      "Pretty\n",
      "It\n",
      "Ca\n",
      "It\n",
      "John\n",
      "Because\n",
      "Rapidly\n",
      "It\n",
      "Yes\n",
      "But\n",
      "Bauerstein\n",
      "No\n",
      "I\n",
      "The\n",
      "Voices\n",
      "I\n",
      "He\n",
      "He\n",
      "An\n",
      "Had\n",
      "She\n",
      "Still\n",
      "I\n",
      "It\n",
      "Did\n",
      "But\n",
      "What\n",
      "Have\n",
      "Well\n",
      "I\n",
      "He\n",
      "It\n",
      "At\n",
      "Parkson\n",
      "It\n",
      "or\n",
      "It\n",
      "It\n",
      "Where\n",
      "It\n",
      "Having\n",
      "She\n",
      "Yes\n",
      "My\n",
      "Yes\n",
      "The\n",
      "Besides\n",
      "It\n",
      "You\n",
      "Our\n",
      "It\n",
      "But\n",
      "Visitors\n",
      "No\n",
      "This\n",
      "Officially\n",
      "I\n",
      "This\n",
      "This\n",
      "She\n",
      "It\n",
      "In\n",
      "It\n",
      "No\n",
      "You\n",
      "You\n",
      "Do\n",
      "Should\n",
      "Should\n",
      "Supposing\n",
      "I\n",
      "How\n",
      "The\n",
      "Where\n",
      "Did\n",
      "Then\n",
      "Yes\n",
      "It\n",
      "And\n",
      "It\n",
      "Elizabeth\n",
      "No\n",
      "It\n",
      "Does\n",
      "In\n",
      "You\n",
      "Then\n",
      "Then\n",
      "They\n",
      "They\n",
      "Cross\n",
      "Sir\n",
      "Not\n",
      "Not\n",
      "Let\n",
      "The\n",
      "Unfortunately\n",
      "Tell\n",
      "Do\n",
      "I\n",
      "It\n",
      "You\n",
      "And\n",
      "If\n",
      "I\n",
      "To\n",
      "I\n",
      "Nor\n",
      "Nor\n",
      "But\n",
      "We\n",
      "She\n",
      "She\n",
      "The\n",
      "and\n",
      "She\n",
      "She\n",
      "Possibly\n",
      "Possibly\n",
      "The\n",
      "I\n",
      "He\n",
      "She\n",
      "I\n",
      "But\n",
      "We\n",
      "It\n",
      "It\n",
      "What\n",
      "What\n",
      "Feeling\n",
      "There\n",
      "It\n",
      "A\n",
      "One\n",
      "You\n",
      "Had\n",
      "As\n",
      "How\n",
      "When\n",
      "but\n",
      "It\n",
      "What\n",
      "If\n",
      "Yes\n",
      "He\n",
      "He\n",
      "Mr.s\n",
      "There\n",
      "There\n",
      "Because\n",
      "That\n",
      "There\n",
      "There\n",
      "Then\n",
      "You\n",
      "But\n",
      "But\n",
      "I\n",
      "I\n",
      "He\n",
      "The\n",
      "The\n",
      "It\n",
      "It\n",
      "But\n",
      "And\n",
      "I\n",
      "It\n",
      "He\n",
      "Pardon\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "for row in data.itertuples():\n",
    "    # print(row)\n",
    "    k = process_row(row)\n",
    "    if k is not None:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734d866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
